{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# prepare feature"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### collect .pdb files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total .pdb file: b'13434\\n'\n"
                    ]
                }
            ],
            "source": [
                "import subprocess\n",
                "\n",
                "data_pdb_path = \"./data/DMS/1AO7/pdb/\"\n",
                "os.makedirs(data_pdb_path, exist_ok=True)\n",
                "\n",
                "os.system(f\"cp ./datasets/DMS/1AO7/cleaned_PDBs/*.pdb {data_pdb_path}\")\n",
                "os.system(f\"cp ./datasets/DMS/1AO7/mut_PDBs/*.pdb {data_pdb_path}\")\n",
                "\n",
                "print(f\"Total .pdb file: {subprocess.check_output(f'ls {data_pdb_path} | wc -w', shell=True)}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### extract sequence & coordinate from .pdb file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "from utils import *\n",
                "\n",
                "from Bio.PDB import PDBParser\n",
                "\n",
                "data_seq_path = \"./data/DMS/1AO7/seq/\"\n",
                "data_coord_path = \"./data/DMS/1AO7/coord/\"\n",
                "os.makedirs(data_seq_path, exist_ok=True)\n",
                "os.makedirs(data_coord_path, exist_ok=True)\n",
                "\n",
                "pdb_list = glob.glob(f\"{data_pdb_path}/*.pdb\")\n",
                "for pdb_filepath in tqdm(pdb_list):\n",
                "    name = os.path.basename(pdb_filepath).split(\".\")[0]\n",
                "    # print(name)\n",
                "    \n",
                "    parser = PDBParser(QUIET=True)\n",
                "    struct = parser.get_structure(name, pdb_filepath)\n",
                "    res_list = get_clean_res_list(struct.get_residues(), verbose=False, ensure_ca_exist=True)\n",
                "    # ensure all res contains N, CA, C and O\n",
                "    res_list = [res for res in res_list if (('N' in res) and ('CA' in res) and ('C' in res) and ('O' in res))]\n",
                "\n",
                "    # extract sequence\n",
                "    seq = \"\".join([three_to_one.get(res.resname) for res in res_list])\n",
                "\n",
                "    # extract coordinate\n",
                "    coord = []\n",
                "    for res in res_list:\n",
                "        res_coord = []\n",
                "        R_group = []\n",
                "        for atom in res:\n",
                "            if atom.get_name() in ['N', 'CA', 'C', 'O']:\n",
                "                res_coord.append(atom.get_coord())\n",
                "            else:\n",
                "                R_group.append(atom.get_coord())\n",
                "\n",
                "        if len(R_group) == 0:\n",
                "            R_group.append(res['CA'].get_coord())\n",
                "        R_group = np.array(R_group).mean(axis=0)\n",
                "        res_coord.append(R_group)\n",
                "        coord.append(res_coord)\n",
                "    coord = np.array(coord)  # convert list directly to tensor would be rather slow, suggest use ndarray as transition\n",
                "    coord = torch.tensor(coord, dtype=torch.float32)\n",
                "\n",
                "    # save to file\n",
                "    seq_to_file = f\"{data_seq_path}/{name}.txt\"\n",
                "    coord_to_file = f\"{data_coord_path}/{name}.pt\"\n",
                "    with open(seq_to_file, \"w\") as seq_file:\n",
                "        seq_file.write(seq)\n",
                "    torch.save(coord, coord_to_file)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### extract ProtTrans feature from sequence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gc\n",
                "from tqdm import tqdm\n",
                "import torch\n",
                "from transformers import T5Tokenizer, T5EncoderModel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at ./tools/Prot-T5-XL-U50/ were not used when initializing T5EncoderModel: ['decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'lm_head.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.embed_tokens.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight']\n",
                        "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
                    ]
                }
            ],
            "source": [
                "ProtTrans_toolpath = \"./tools/Prot-T5-XL-U50/\"\n",
                "gpu = '1'\n",
                "\n",
                "# Load the vocabulary and ProtT5-XL-UniRef50 Model\n",
                "tokenizer = T5Tokenizer.from_pretrained(ProtTrans_toolpath, do_lower_case=False)\n",
                "model = T5EncoderModel.from_pretrained(ProtTrans_toolpath)\n",
                "gc.collect()\n",
                "\n",
                "# Load the model into the GPU if avilabile and switch to inference mode\n",
                "device = torch.device('cuda:' + gpu if torch.cuda.is_available() and gpu else 'cpu')\n",
                "model = model.to(device)\n",
                "model = model.eval()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13434/13434 [34:35<00:00,  6.47it/s] \n"
                    ]
                }
            ],
            "source": [
                "data_seq_path = \"./data/DMS/1AO7/seq/\"\n",
                "\n",
                "data_ProtTrans_raw_path = \"./data/DMS/1AO7/ProtTrans_raw/\"\n",
                "os.makedirs(data_ProtTrans_raw_path, exist_ok=True)\n",
                "\n",
                "pdb_list = glob.glob(f\"{data_pdb_path}/*.pdb\")\n",
                "name_list = [os.path.basename(pdb_filepath).split(\".\")[0] for pdb_filepath in pdb_list]\n",
                "\n",
                "for name in tqdm(name_list):\n",
                "    # ProtTrans_to_file = f\"{data_ProtTrans_raw_path}/{name}.npy\"\n",
                "    # if os.path.exists(ProtTrans_to_file):\n",
                "    #     continue\n",
                "    with open(f\"{data_seq_path}/{name}.txt\") as seq_file:\n",
                "        seq = seq_file.readline()\n",
                "    batch_name_list = [name]\n",
                "    batch_seq_list = [\" \".join(list(seq))]\n",
                "    # print(len(seq))\n",
                "    # print(batch_name_list)\n",
                "    # print(batch_seq_list)\n",
                "\n",
                "    # Tokenize, encode sequences and load it into the GPU if possibile\n",
                "    ids = tokenizer.batch_encode_plus(batch_seq_list, add_special_tokens=True, padding=True)\n",
                "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
                "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
                "\n",
                "    # Extracting sequences' features and load it into the CPU if needed\n",
                "    with torch.no_grad():\n",
                "        embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
                "    embedding = embedding.last_hidden_state.cpu()\n",
                "\n",
                "    # Remove padding (\\<pad>) and special tokens (\\</s>) that is added by ProtT5-XL-UniRef50 model\n",
                "    for seq_num in range(len(embedding)):\n",
                "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
                "        seq_emb = embedding[seq_num][:seq_len-1]\n",
                "        # print(f\"truncate padding: {embedding[seq_num].shape} -> {seq_emb.shape}\")\n",
                "        ProtTrans_to_file = f\"{data_ProtTrans_raw_path}/{batch_name_list[seq_num]}.npy\"\n",
                "        np.save(ProtTrans_to_file, seq_emb)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### normalize raw ProtTrans"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13434/13434 [07:39<00:00, 29.24it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[-0.9715796 -0.53459   -0.7825786 ... -0.7357477 -0.7062289 -0.7532639]\n",
                        "[0.6705426  0.6439474  0.8558858  ... 0.924354   0.8515873  0.69065195]\n"
                    ]
                }
            ],
            "source": [
                "Max_protrans = []\n",
                "Min_protrans = []\n",
                "for name in tqdm(name_list):\n",
                "    raw_protrans = np.load(f\"{data_ProtTrans_raw_path}/{name}.npy\")\n",
                "    Max_protrans.append(np.max(raw_protrans, axis = 0))\n",
                "    Min_protrans.append(np.min(raw_protrans, axis = 0))\n",
                "\n",
                "Min_protrans = np.min(np.array(Min_protrans), axis = 0)\n",
                "Max_protrans = np.max(np.array(Max_protrans), axis = 0)\n",
                "print(Min_protrans)\n",
                "print(Max_protrans)\n",
                "\n",
                "np.save(\"./data/DMS/1AO7/Max_ProtTrans_repr.npy\", Max_protrans)\n",
                "np.save(\"./data/DMS/1AO7/Min_ProtTrans_repr.npy\", Min_protrans)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/13434 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13434/13434 [10:53<00:00, 20.57it/s] \n"
                    ]
                }
            ],
            "source": [
                "Max_protrans = np.load(\"./data/DMS/1AO7/Max_ProtTrans_repr.npy\")\n",
                "Min_protrans = np.load(\"./data/DMS/1AO7/Min_ProtTrans_repr.npy\")\n",
                "\n",
                "data_ProtTrans_path = \"./data/DMS/1AO7/ProtTrans/\"\n",
                "os.makedirs(data_ProtTrans_path, exist_ok=True)\n",
                "\n",
                "for name in tqdm(name_list):\n",
                "    raw_protrans = np.load(f\"{data_ProtTrans_raw_path}/{name}.npy\")\n",
                "    protrans = (raw_protrans - Min_protrans) / (Max_protrans - Min_protrans)\n",
                "    ProtTrans_to_file = f\"{data_ProtTrans_path}/{name}.pt\"\n",
                "    torch.save(torch.tensor(protrans, dtype = torch.float32), ProtTrans_to_file)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### extract DSSP feature from .pdb file"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### correct format of mut.pdb: col of Occupancy(55 - 60) should be \"{:.2f}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13434/13434 [08:42<00:00, 25.73it/s]\n"
                    ]
                }
            ],
            "source": [
                "data_pdb_path = \"./data/DMS/1AO7/pdb/\"\n",
                "\n",
                "for name in tqdm(name_list):\n",
                "    pdb_filepath = f\"{data_pdb_path}/{name}.pdb\"\n",
                "\n",
                "    with open(pdb_filepath, \"r\") as f:\n",
                "        lines = f.readlines()\n",
                "\n",
                "    for i in range(len(lines)):\n",
                "        if lines[i].split()[0] == \"REMARK\":\n",
                "            continue\n",
                "        lines[i] = lines[i][:57] + '.00' + lines[i][60:]\n",
                "\n",
                "    with open(pdb_filepath, \"w\") as f:\n",
                "        f.writelines(lines)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13434/13434 [21:48<00:00, 10.27it/s]\n"
                    ]
                }
            ],
            "source": [
                "from utils import *\n",
                "\n",
                "data_pdb_path = \"./data/DMS/1AO7/pdb/\"\n",
                "data_seq_path = \"./data/DMS/1AO7/seq/\"\n",
                "dssp_toolpath = \"./tools/mkdssp\"\n",
                "\n",
                "data_DSSP_path = \"./data/DMS/1AO7/DSSP\"\n",
                "os.makedirs(data_DSSP_path, exist_ok=True)\n",
                "\n",
                "for name in tqdm(name_list):\n",
                "    pdb_filepath = f\"{data_pdb_path}/{name}.pdb\"\n",
                "    with open(f\"{data_seq_path}/{name}.txt\") as seq_file:\n",
                "        seq = seq_file.readline()\n",
                "\n",
                "    DSSP_to_file = f\"{data_DSSP_path}/{name}.dssp\"\n",
                "    dssp_cmd = f\"{dssp_toolpath} -i {pdb_filepath} -o {DSSP_to_file}\"\n",
                "    os.system(dssp_cmd)\n",
                "\n",
                "    try:\n",
                "        dssp_seq, dssp_matrix = process_dssp(DSSP_to_file)\n",
                "        # dssp_seq: likely equal to original sequence\n",
                "        # dssp_matrix (list<ndarray>): list of (1, 9) vector, length of dssp_seq\n",
                "        if dssp_seq != seq:\n",
                "            dssp_matrix = match_dssp(dssp_seq, dssp_matrix, seq)\n",
                "        \n",
                "        DSSP_to_file = f\"{data_DSSP_path}/{name}.pt\"\n",
                "        torch.save(torch.tensor(np.array(dssp_matrix), dtype = torch.float32), DSSP_to_file)\n",
                "        # shape(AA_len, 9)\n",
                "        # os.system(\"rm {DSSP_to_file}\"\")\n",
                "    except:\n",
                "        print(f\"Wrong entry prompt: $ {dssp_cmd}\")\n",
                "        continue\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# prepare dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>mut_name</th>\n",
                            "      <th>wt_name</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1AO7_GE61I</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1AO7_SD25Q</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1AO7_NE26A</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1AO7_LB40K</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1AO7_SE82R</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13428</th>\n",
                            "      <td>1AO7_FA208I</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13429</th>\n",
                            "      <td>1AO7_LA126S</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13430</th>\n",
                            "      <td>1AO7_PA235M</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13431</th>\n",
                            "      <td>1AO7_RA234P</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13432</th>\n",
                            "      <td>1AO7_SD31W</td>\n",
                            "      <td>1AO7</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>13433 rows × 2 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          mut_name wt_name\n",
                            "0       1AO7_GE61I    1AO7\n",
                            "1       1AO7_SD25Q    1AO7\n",
                            "2       1AO7_NE26A    1AO7\n",
                            "3       1AO7_LB40K    1AO7\n",
                            "4       1AO7_SE82R    1AO7\n",
                            "...            ...     ...\n",
                            "13428  1AO7_FA208I    1AO7\n",
                            "13429  1AO7_LA126S    1AO7\n",
                            "13430  1AO7_PA235M    1AO7\n",
                            "13431  1AO7_RA234P    1AO7\n",
                            "13432   1AO7_SD31W    1AO7\n",
                            "\n",
                            "[13433 rows x 2 columns]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import glob\n",
                "import pandas as pd\n",
                "import torch\n",
                "\n",
                "df = pd.DataFrame()\n",
                "df[\"mut_name\"] = glob.glob(\"./data/DMS/1AO7/pdb/1AO7_*.pdb\")\n",
                "df[\"mut_name\"] = df[\"mut_name\"].apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
                "df[\"wt_name\"] = \"1AO7\"\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.save(df, \"./data/DMS/1AO7/mut_wt_pairs.pt\")"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
